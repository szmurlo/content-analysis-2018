{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 - Information Extraction\n",
    "\n",
    "\n",
    "This week, we move from arbitrary textual classification to the use of computation and linguistic models to parse precise claims from documents. Rather than focusing on simply the *ideas* in a corpus, here we focus on understanding and extracting its precise *claims*. This process involves a sequential pipeline of classifying and structuring tokens from text, each of which generates potentially useful data for the content analyst. Steps in this process, which we examine in this notebook, include: 1) tagging words by their part of speech (POS) to reveal the linguistic role they play in the sentence (e.g., Verb, Noun, Adjective, etc.); 2) tagging words as named entities (NER) such as places or organizations; 3) structuring or \"parsing\" sentences into nested phrases that are local to, describe or depend on one another; and 4) extracting informational claims from those phrases, like the Subject-Verb-Object (SVO) triples we extract here. While much of this can be done directly in the python package NLTK that we introduced in week 2, here we use NLTK bindings to the Stanford NLP group's open software, written in Java. Try typing a sentence into the online version [here](http://nlp.stanford.edu:8080/corenlp/) to get a sense of its potential. It is superior in performance to NLTK's implementations, but takes time to run, and so for these exercises we will parse and extract information for a very small text corpus. Of course, for final projects that draw on these tools, we encourage you to install the software on your own machines or shared servers at the university (RCC, SSRC) in order to perform these operations on much more text. \n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to run this _once_ to download everything, you will also need [Java 1.8+](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) if you are using Windows or MacOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting downloads, this will take 5-10 minutes\n",
      "../stanford-NLP/parser already exists, skipping download\n",
      "../stanford-NLP/ner already exists, skipping download\n",
      "../stanford-NLP/postagger already exists, skipping download\n",
      "../stanford-NLP/core already exists, skipping download\n",
      "[100%]Done setting up the Stanford NLP collection\n"
     ]
    }
   ],
   "source": [
    "lucem_illud.setupStanfordNLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have stanford-NLP setup before importing, so we are doing the import here. IF you have stanford-NLP working, you can import at the beginning like you would with any other library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/Anaconda3-5.0.0.1-el7-x86_64/lib/python3.6/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "/software/Anaconda3-5.0.0.1-el7-x86_64/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Information Extraction is a module packaged within the Stanford Core NLP package, but it is not yet supported by `nltk`. As a result, we have defining our own `lucem_illud` function that runs the Stanford Core NLP java code right here. For other projects, it is often useful to use Java or other programs (in C, C++) within a python workflow, and this is an example. `stanford.openIE()` takes in a string or list of strings and then produces as output all the subject, verb, object (SVO) triples Stanford Corenlp can find, as a DataFrame. You can do this through links to the Stanford Core NLP project that we provide here, or play with their interface directly (in the penultimate cell of this notebook), which produces data in \"pretty graphics\" like this example parsing of the first sentence in the \"Shooting of Trayvon Martin\" Wikipedia article:\n",
    "\n",
    "![Output 1](../data/stanford_core1.png)\n",
    "![Output 2](../data/stanford_core2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will illustrate these tools on some *very* short examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the elephant in my pajamas.\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.\n",
      "Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [nltk.word_tokenize(t) for t in text]\n",
    "print('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In POS tagging, we classify each word by its semantic role in a sentence. The Stanford POS tagger uses the [Penn Treebank tag set]('http://repository.upenn.edu/cgi/viewcontent.cgi?article=1603&context=cis_reports') to POS tag words from input sentences. As discussed in the second assignment, this is a relatively precise tagset, which allows more informative tags, and also more opportunities to err :-).\n",
    "\n",
    "|#. |Tag |Description |\n",
    "|---|----|------------|\n",
    "|1.\t|CC\t|Coordinating conjunction\n",
    "|2.\t|CD\t|Cardinal number\n",
    "|3.\t|DT\t|Determiner\n",
    "|4.\t|EX\t|Existential there\n",
    "|5.\t|FW\t|Foreign word\n",
    "|6.\t|IN\t|Preposition or subordinating conjunction\n",
    "|7.\t|JJ\t|Adjective\n",
    "|8.\t|JJR|\tAdjective, comparative\n",
    "|9.\t|JJS|\tAdjective, superlative\n",
    "|10.|\tLS\t|List item marker\n",
    "|11.|\tMD\t|Modal\n",
    "|12.|\tNN\t|Noun, singular or mass\n",
    "|13.|\tNNS\t|Noun, plural\n",
    "|14.|\tNNP\t|Proper noun, singular\n",
    "|15.|\tNNPS|\tProper noun, plural\n",
    "|16.|\tPDT\t|Predeterminer\n",
    "|17.|\tPOS\t|Possessive ending\n",
    "|18.|\tPRP\t|Personal pronoun\n",
    "|19.|\tPRP\\$|\tPossessive pronoun\n",
    "|20.|\tRB\t|Adverb\n",
    "|21.|\tRBR\t|Adverb, comparative\n",
    "|22.|\tRBS\t|Adverb, superlative\n",
    "|23.|\tRP\t|Particle\n",
    "|24.|\tSYM\t|Symbol\n",
    "|25.|\tTO\t|to\n",
    "|26.|\tUH\t|Interjection\n",
    "|27.|\tVB\t|Verb, base form\n",
    "|28.|\tVBD\t|Verb, past tense\n",
    "|29.|\tVBG\t|Verb, gerund or present participle\n",
    "|30.|\tVBN\t|Verb, past participle\n",
    "|31.|\tVBP\t|Verb, non-3rd person singular present\n",
    "|32.|\tVBZ\t|Verb, 3rd person singular present\n",
    "|33.|\tWDT\t|Wh-determiner\n",
    "|34.|\tWP\t|Wh-pronoun\n",
    "|35.|\tWP$\t|Possessive wh-pronoun\n",
    "|36.|\tWRB\t|Wh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'PRP'), ('saw', 'VBD'), ('the', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NNS'), ('.', '.')], [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')], [('While', 'IN'), ('in', 'IN'), ('France', 'NNP'), (',', ','), ('Christine', 'NNP'), ('Lagarde', 'NNP'), ('discussed', 'VBD'), ('short-term', 'JJ'), ('stimulus', 'NN'), ('efforts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Wall', 'NNP'), ('Street', 'NNP'), ('Journal', 'NNP'), ('.', '.')], [('Trayvon', 'NNP'), ('Benjamin', 'NNP'), ('Martin', 'NNP'), ('was', 'VBD'), ('an', 'DT'), ('African', 'NNP'), ('American', 'NNP'), ('from', 'IN'), ('Miami', 'NNP'), ('Gardens', 'NNP'), (',', ','), ('Florida', 'NNP'), (',', ','), ('who', 'WP'), (',', ','), ('at', 'IN'), ('17', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('was', 'VBD'), ('fatally', 'RB'), ('shot', 'VBN'), ('by', 'IN'), ('George', 'NNP'), ('Zimmerman', 'NNP'), (',', ','), ('a', 'DT'), ('neighborhood', 'NN'), ('watch', 'NN'), ('volunteer', 'NN'), (',', ','), ('in', 'IN'), ('Sanford', 'NNP'), (',', ','), ('Florida', 'NNP'), ('.', '.')], [('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "pos_sents = stanford.postTagger.tag_sents(tokenized_text)\n",
    "print(pos_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite good. Now we will try POS tagging with a somewhat larger corpus. We consider a few of the top posts from the reddit data we used last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditDF = pandas.read_csv('../data/reddit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the 10 highest scoring posts and tokenizing the sentences. Once again, notice that we aren't going to do any kind of stemming this week (although *semantic* normalization may be performed where we translate synonyms into the same focal word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>over_18</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goldie-gold</td>\n",
       "      <td>False</td>\n",
       "      <td>12650</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>This just happened...  So, I had a laptop syst...</td>\n",
       "      <td>Engineer is doing drugs!! No. No they aren't.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[This, just, happened, ...], [So, ,, I, had, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheDroolinFool</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Another tale from the out of hours IT desk... ...</td>\n",
       "      <td>\"I need you to fix Google Bing immediately!\"</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Another, tale, from, the, out, of, hours, IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clickity_clickity</td>\n",
       "      <td>False</td>\n",
       "      <td>13404</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>[Part 1](http://www.reddit.com/r/talesfromtech...</td>\n",
       "      <td>Jack, the Worst End User, Part 4</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[[, Part, 1, ], (, http, :, //www.reddit.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECGaz</td>\n",
       "      <td>False</td>\n",
       "      <td>13724</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>&gt; $Me  - Hello, IT.   &gt; $Usr - Hi, I am still ...</td>\n",
       "      <td>Hi, I am still off sick but I am not.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[&gt;, $, Me, -, Hello, ,, IT, .], [&gt;, $, Usr, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guitarsdontdance</td>\n",
       "      <td>False</td>\n",
       "      <td>14089</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>So my story starts on what was a normal day ta...</td>\n",
       "      <td>\"Don't bother sending a tech, I'll be dead by ...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[So, my, story, starts, on, what, was, a, nor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  over_18  score                subreddit  \\\n",
       "4        goldie-gold    False  12650  Tales From Tech Support   \n",
       "3     TheDroolinFool    False  13152  Tales From Tech Support   \n",
       "2  Clickity_clickity    False  13404  Tales From Tech Support   \n",
       "1             SECGaz    False  13724  Tales From Tech Support   \n",
       "0   guitarsdontdance    False  14089  Tales From Tech Support   \n",
       "\n",
       "                                                text  \\\n",
       "4  This just happened...  So, I had a laptop syst...   \n",
       "3  Another tale from the out of hours IT desk... ...   \n",
       "2  [Part 1](http://www.reddit.com/r/talesfromtech...   \n",
       "1  > $Me  - Hello, IT.   > $Usr - Hi, I am still ...   \n",
       "0  So my story starts on what was a normal day ta...   \n",
       "\n",
       "                                               title  \\\n",
       "4      Engineer is doing drugs!! No. No they aren't.   \n",
       "3       \"I need you to fix Google Bing immediately!\"   \n",
       "2                   Jack, the Worst End User, Part 4   \n",
       "1              Hi, I am still off sick but I am not.   \n",
       "0  \"Don't bother sending a tech, I'll be dead by ...   \n",
       "\n",
       "                                                 url  \\\n",
       "4  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "3  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "2  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "1  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "0  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "\n",
       "                                           sentences  \n",
       "4  [[This, just, happened, ...], [So, ,, I, had, ...  \n",
       "3  [[Another, tale, from, the, out, of, hours, IT...  \n",
       "2  [[[, Part, 1, ], (, http, :, //www.reddit.com/...  \n",
       "1  [[>, $, Me, -, Hello, ,, IT, .], [>, $, Usr, -...  \n",
       "0  [[So, my, story, starts, on, what, was, a, nor...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores = redditDF.sort_values('score')[-10:]\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores.index = range(len(redditTopScores) - 1, -1,-1) #Reindex to make things nice in the future\n",
    "redditTopScores[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, JJ), (year, NN), (,, ,), (Help, NN), ...\n",
       "8    [[(First, JJ), (post, NN), (in, IN), (quite, R...\n",
       "7    [[([, NNP), (Original, NNP), (Post, NNP), (], ...\n",
       "6    [[(I, PRP), (witnessed, VBD), (this, DT), (ast...\n",
       "5    [[(I, PRP), (work, VBP), (Helpdesk, NNP), (for...\n",
       "4    [[(This, DT), (just, RB), (happened, VBN), (.....\n",
       "3    [[(Another, DT), (tale, NN), (from, IN), (the,...\n",
       "2    [[([, NNP), (Part, NNP), (1, CD), (], FW), ((,...\n",
       "1    [[(>, JJR), ($, $), (Me, PRP), (-, :), (Hello,...\n",
       "0    [[(So, RB), (my, PRP$), (story, NN), (starts, ...\n",
       "Name: POS_sents, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And count the number of `NN` (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('password', 21),\n",
       " ('(', 19),\n",
       " ('time', 14),\n",
       " (')', 14),\n",
       " ('lot', 12),\n",
       " ('computer', 12),\n",
       " ('life', 11),\n",
       " ('email', 11),\n",
       " ('**Genius**', 10),\n",
       " ('message', 9),\n",
       " ('**Me**', 9),\n",
       " ('system', 9),\n",
       " ('day', 9),\n",
       " ('call', 8),\n",
       " ('laptop', 8),\n",
       " ('office', 8),\n",
       " ('part', 8),\n",
       " ('today', 8),\n",
       " ('story', 8),\n",
       " ('user', 7)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the number of top verbs (`VB`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 18),\n",
       " ('have', 17),\n",
       " ('get', 14),\n",
       " ('do', 11),\n",
       " ('change', 9),\n",
       " ('make', 8),\n",
       " ('know', 7),\n",
       " ('say', 7),\n",
       " ('help', 6),\n",
       " ('look', 6),\n",
       " ('tell', 6),\n",
       " ('send', 6),\n",
       " ('go', 5),\n",
       " ('work', 4),\n",
       " ('use', 4),\n",
       " ('receive', 4),\n",
       " ('thank', 4),\n",
       " ('feel', 4),\n",
       " ('want', 4),\n",
       " ('call', 4)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the adjectives that modify the word, \"computer\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unrestricted', 'own'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'computer'\n",
    "NResults = set()\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating POS tagger\n",
    "\n",
    "We can check the POS tagger by running it on a manually tagged corpus and identifying a reasonable error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('61', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('will', 'MD'),\n",
       "  ('join', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('board', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('Nov.', 'NNP'),\n",
       "  ('29', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Elsevier', 'NNP'),\n",
       "  ('N.V.', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('Dutch', 'NNP'),\n",
       "  ('publishing', 'VBG'),\n",
       "  ('group', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NNP'),\n",
       "  ('Agnew', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('55', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('former', 'JJ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Consolidated', 'NNP'),\n",
       "  ('Gold', 'NNP'),\n",
       "  ('Fields', 'NNP'),\n",
       "  ('PLC', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('was', 'VBD'),\n",
       "  ('named', 'VBN'),\n",
       "  ('*-1', '-NONE-'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('British', 'JJ'),\n",
       "  ('industrial', 'JJ'),\n",
       "  ('conglomerate', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DT'),\n",
       "  ('form', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('asbestos', 'NN'),\n",
       "  ('once', 'RB'),\n",
       "  ('used', 'VBN'),\n",
       "  ('*', '-NONE-'),\n",
       "  ('*', '-NONE-'),\n",
       "  ('to', 'TO'),\n",
       "  ('make', 'VB'),\n",
       "  ('Kent', 'NNP'),\n",
       "  ('cigarette', 'NN'),\n",
       "  ('filters', 'NNS'),\n",
       "  ('has', 'VBZ'),\n",
       "  ('caused', 'VBN'),\n",
       "  ('a', 'DT'),\n",
       "  ('high', 'JJ'),\n",
       "  ('percentage', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('cancer', 'NN'),\n",
       "  ('deaths', 'NNS'),\n",
       "  ('among', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('group', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('workers', 'NNS'),\n",
       "  ('exposed', 'VBN'),\n",
       "  ('*', '-NONE-'),\n",
       "  ('to', 'TO'),\n",
       "  ('it', 'PRP'),\n",
       "  ('more', 'RBR'),\n",
       "  ('than', 'IN'),\n",
       "  ('30', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('ago', 'IN'),\n",
       "  (',', ','),\n",
       "  ('researchers', 'NNS'),\n",
       "  ('reported', 'VBD'),\n",
       "  ('0', '-NONE-'),\n",
       "  ('*T*-1', '-NONE-'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DT'),\n",
       "  ('asbestos', 'NN'),\n",
       "  ('fiber', 'NN'),\n",
       "  (',', ','),\n",
       "  ('crocidolite', 'NN'),\n",
       "  (',', ','),\n",
       "  ('is', 'VBZ'),\n",
       "  ('unusually', 'RB'),\n",
       "  ('resilient', 'JJ'),\n",
       "  ('once', 'IN'),\n",
       "  ('it', 'PRP'),\n",
       "  ('enters', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('lungs', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('with', 'IN'),\n",
       "  ('even', 'RB'),\n",
       "  ('brief', 'JJ'),\n",
       "  ('exposures', 'NNS'),\n",
       "  ('to', 'TO'),\n",
       "  ('it', 'PRP'),\n",
       "  ('causing', 'VBG'),\n",
       "  ('symptoms', 'NNS'),\n",
       "  ('that', 'WDT'),\n",
       "  ('*T*-1', '-NONE-'),\n",
       "  ('show', 'VBP'),\n",
       "  ('up', 'RP'),\n",
       "  ('decades', 'NNS'),\n",
       "  ('later', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('researchers', 'NNS'),\n",
       "  ('said', 'VBD'),\n",
       "  ('0', '-NONE-'),\n",
       "  ('*T*-2', '-NONE-'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank = nltk.corpus.treebank\n",
    "treeBank.tagged_sents()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanfordTags = stanford.postTagger.tag_sents(treeBank.sents()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Dutch  \tStanford: JJ\tTreebank: NNP\n",
      "Word: publishing  \tStanford: NN\tTreebank: VBG\n",
      "Word: used  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: later  \tStanford: RB\tTreebank: JJ\n",
      "Word: New  \tStanford: NNP\tTreebank: JJ\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: replaced  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: JJ\n",
      "Word: expected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: study  \tStanford: VBD\tTreebank: VBP\n",
      "Word: studied  \tStanford: VBD\tTreebank: VBN\n",
      "Word: industrialized  \tStanford: JJ\tTreebank: VBN\n",
      "Word: Lorillard  \tStanford: NNP\tTreebank: NN\n",
      "Word: found  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: rejected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: poured  \tStanford: VBN\tTreebank: VBD\n",
      "Word: in  \tStanford: IN\tTreebank: RP\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "The Precision is 96.547%\n"
     ]
    }
   ],
   "source": [
    "NumDiffs = 0\n",
    "for sentIndex in range(len(stanfordTags)):\n",
    "    for wordIndex in range(len(stanfordTags[sentIndex])):\n",
    "        if stanfordTags[sentIndex][wordIndex][1] != treeBank.tagged_sents()[sentIndex][wordIndex][1]:\n",
    "            if treeBank.tagged_sents()[sentIndex][wordIndex][1] != '-NONE-':\n",
    "                print(\"Word: {}  \\tStanford: {}\\tTreebank: {}\".format(stanfordTags[sentIndex][wordIndex][0], stanfordTags[sentIndex][wordIndex][1], treeBank.tagged_sents()[sentIndex][wordIndex][1]))\n",
    "                NumDiffs += 1\n",
    "total = sum([len(s) for s in stanfordTags])\n",
    "print(\"The Precision is {:.3f}%\".format((total-NumDiffs)/total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the stanford POS tagger is quite good. Nevertheless, for a 20 word sentence, we only have a 66% chance ($1-.96^{20}$) of tagging (and later parsing) it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform POS tagging on a meaningful (but modest) subset of a corpus associated with your final project. Examine the list of words associated with at least three different parts of speech. Consider conditional frequencies (e.g., adjectives associated with nouns of interest or adverbs with verbs of interest). What do these distributions suggest about your corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting seeing how Microsoft classifies their business and likely could provide information when comparing across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners and e...</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS, AND ...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>TO OUR SHAREHOLDERS, CUSTOM ERS, PARTNERS AND ...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Dear shareholders, customers, partners, and em...</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Dear shareholders, customers, partners and emp...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        company                                               text  year  a\n",
       "27   Microsoft   To our shareholders, customers, partners, and ...  2005  1\n",
       "35   Microsoft   To our shareholders, customers, partners, and ...  2006  1\n",
       "46   Microsoft   To our shareholders, customers, partners and e...  2007  1\n",
       "61   Microsoft   To our shareholders, customers, partners, and ...  2008  1\n",
       "77   Microsoft   To our shareholders, customers, partners, and ...  2009  1\n",
       "127  Microsoft   TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS, AND ...  2011  1\n",
       "151  Microsoft   TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...  2012  1\n",
       "176  Microsoft   TO OUR SHAREHOLDERS, CUSTOM ERS, PARTNERS AND ...  2013  1\n",
       "203  Microsoft   TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...  2014  1\n",
       "255  Microsoft   Dear shareholders, customers, partners, and em...  2016  1\n",
       "264  Microsoft   Dear shareholders, customers, partners and emp...  2017  1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original data\n",
    "letters = pandas.read_pickle('/home/szmurlo/Downloads/pandasDF.pkl')\n",
    "letters['a'] = 0\n",
    "letters.head(20)\n",
    "for index, row in letters.iterrows():\n",
    "\n",
    "    if 'Microsoft' in row['company']:\n",
    "        letters.loc[index,'a'] = 1\n",
    "\n",
    "#microsoft letters\n",
    "microsoft =letters.loc[letters['a']==1]\n",
    "#removing bad data\n",
    "microsoft= microsoft[microsoft.index!=21]\n",
    "microsoft=microsoft[microsoft.index!=230]\n",
    "microsoft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>a</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>[[TO, OUR, SHAREHOLDERS, ,, CUSTOMERS, ,, PART...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>TO OUR SHAREHOLDERS, CUSTOM ERS, PARTNERS AND ...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>[[TO, OUR, SHAREHOLDERS, ,, CUSTOM, ERS, ,, PA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>[[TO, OUR, SHAREHOLDERS, ,, CUSTOMERS, ,, PART...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Dear shareholders, customers, partners, and em...</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Dear, shareholders, ,, customers, ,, partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Dear shareholders, customers, partners and emp...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Dear, shareholders, ,, customers, ,, partner...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company                                               text  year  a  \\\n",
       "4  Microsoft   TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...  2012  1   \n",
       "3  Microsoft   TO OUR SHAREHOLDERS, CUSTOM ERS, PARTNERS AND ...  2013  1   \n",
       "2  Microsoft   TO OUR SHAREHOLDERS, CUSTOMERS, PARTNERS AND E...  2014  1   \n",
       "1  Microsoft   Dear shareholders, customers, partners, and em...  2016  1   \n",
       "0  Microsoft   Dear shareholders, customers, partners and emp...  2017  1   \n",
       "\n",
       "                                           sentences  \n",
       "4  [[TO, OUR, SHAREHOLDERS, ,, CUSTOMERS, ,, PART...  \n",
       "3  [[TO, OUR, SHAREHOLDERS, ,, CUSTOM, ERS, ,, PA...  \n",
       "2  [[TO, OUR, SHAREHOLDERS, ,, CUSTOMERS, ,, PART...  \n",
       "1  [[Dear, shareholders, ,, customers, ,, partner...  \n",
       "0  [[Dear, shareholders, ,, customers, ,, partner...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microsoft['sentences'] = microsoft['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "microsoft.index = range(len(microsoft) - 1, -1,-1) #Reindex to make things nice in the future\n",
    "microsoft[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "microsoft['POS_sents'] = microsoft['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 95),\n",
       " ('business', 82),\n",
       " ('technology', 81),\n",
       " ('growth', 69),\n",
       " ('software', 66),\n",
       " ('cloud', 61),\n",
       " ('world', 58),\n",
       " ('percent', 57),\n",
       " ('company', 53),\n",
       " ('revenue', 52),\n",
       " ('â\\x80\\x94', 43),\n",
       " ('opportunity', 38),\n",
       " ('computing', 38),\n",
       " ('Server', 37),\n",
       " ('work', 32),\n",
       " ('information', 30),\n",
       " ('search', 29),\n",
       " ('development', 28),\n",
       " ('way', 28),\n",
       " ('innovation', 28)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nouns\n",
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in microsoft['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 46),\n",
       " ('help', 36),\n",
       " ('deliver', 22),\n",
       " ('drive', 21),\n",
       " ('enable', 20),\n",
       " ('create', 19),\n",
       " ('continue', 18),\n",
       " ('make', 18),\n",
       " ('build', 18),\n",
       " ('achieve', 15),\n",
       " ('grow', 13),\n",
       " ('Search', 12),\n",
       " ('bring', 12),\n",
       " ('use', 10),\n",
       " ('transform', 10),\n",
       " ('empower', 10),\n",
       " ('provide', 9),\n",
       " ('change', 9),\n",
       " ('Thank', 9),\n",
       " ('have', 9)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verbs\n",
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in microsoft['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 183),\n",
       " ('fiscal', 57),\n",
       " ('important', 42),\n",
       " ('digital', 33),\n",
       " ('strong', 31),\n",
       " ('past', 29),\n",
       " ('mobile', 28),\n",
       " ('such', 26),\n",
       " ('many', 23),\n",
       " ('economic', 23),\n",
       " ('other', 22),\n",
       " ('global', 19),\n",
       " ('next', 18),\n",
       " ('key', 17),\n",
       " ('great', 17),\n",
       " ('significant', 15),\n",
       " ('future', 13),\n",
       " ('innovative', 13),\n",
       " ('incredible', 13),\n",
       " ('natural', 13)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adjectives\n",
    "#verbs\n",
    "countTarget = 'JJ'\n",
    "targetCounts = {}\n",
    "for entry in microsoft['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'massive', 'small', 'major', 'difficult', 'Essential', 'hardware-centric', 'disruptive', 'large', 'modular', 'new', 'Internet-based'}\n"
     ]
    }
   ],
   "source": [
    "#adjectives that modify business\n",
    "NTarget = 'JJ'\n",
    "Word = 'business'\n",
    "NResults = set()\n",
    "for entry in microsoft['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named-Entity Recognition\n",
    "\n",
    "Named Entity Recognition (NER) is also a classification task, which identifies named objects. Included with Stanford NER are a 4 class model trained on the CoNLL 2003 eng.train, a 7 class model trained on the MUC 6 and MUC 7 training data sets, and a 3 class model trained on both data sets plus some additional data (including ACE 2002 and limited data in-house) on the intersection of those class sets. \n",
    "\n",
    "**3 class**:\tLocation, Person, Organization\n",
    "\n",
    "**4 class**:\tLocation, Person, Organization, Misc\n",
    "\n",
    "**7 class**:\tLocation, Person, Organization, Money, Percent, Date, Time\n",
    "\n",
    "These models each use distributional similarity features, which provide some performance gain at the cost of increasing their size and runtime. Also available are the same models missing those features.\n",
    "\n",
    "(We note that the training data for the 3 class model does not include any material from the CoNLL eng.testa or eng.testb data sets, nor any of the MUC 6 or 7 test or devtest datasets, nor Alan Ritter's Twitter NER data, so all of these would be valid tests of its performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we tag our first set of exemplary sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'O'), ('saw', 'O'), ('the', 'O'), ('elephant', 'O'), ('in', 'O'), ('my', 'O'), ('pajamas', 'O'), ('.', 'O')], [('The', 'O'), ('quick', 'O'), ('brown', 'O'), ('fox', 'O'), ('jumped', 'O'), ('over', 'O'), ('the', 'O'), ('lazy', 'O'), ('dog', 'O'), ('.', 'O')], [('While', 'O'), ('in', 'O'), ('France', 'LOCATION'), (',', 'O'), ('Christine', 'PERSON'), ('Lagarde', 'PERSON'), ('discussed', 'O'), ('short-term', 'O'), ('stimulus', 'O'), ('efforts', 'O'), ('in', 'O'), ('a', 'O'), ('recent', 'O'), ('interview', 'O'), ('with', 'O'), ('the', 'O'), ('Wall', 'ORGANIZATION'), ('Street', 'ORGANIZATION'), ('Journal', 'ORGANIZATION'), ('.', 'O')], [('Trayvon', 'PERSON'), ('Benjamin', 'PERSON'), ('Martin', 'PERSON'), ('was', 'O'), ('an', 'O'), ('African', 'O'), ('American', 'O'), ('from', 'O'), ('Miami', 'LOCATION'), ('Gardens', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), (',', 'O'), ('who', 'O'), (',', 'O'), ('at', 'O'), ('17', 'O'), ('years', 'O'), ('old', 'O'), (',', 'O'), ('was', 'O'), ('fatally', 'O'), ('shot', 'O'), ('by', 'O'), ('George', 'PERSON'), ('Zimmerman', 'PERSON'), (',', 'O'), ('a', 'O'), ('neighborhood', 'O'), ('watch', 'O'), ('volunteer', 'O'), (',', 'O'), ('in', 'O'), ('Sanford', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), ('.', 'O')], [('Buffalo', 'LOCATION'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O'), ('buffalo', 'O'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "classified_sents = stanford.nerTagger.tag_sents(tokenized_text)\n",
    "print(classified_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run NER over our entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditTopScores['classified_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, O), (year, O), (,, O), (Help, O), (De...\n",
       "8    [[(First, O), (post, O), (in, O), (quite, O), ...\n",
       "7    [[([, O), (Original, O), (Post, O), (], O), ((...\n",
       "6    [[(I, O), (witnessed, O), (this, O), (astoundi...\n",
       "5    [[(I, O), (work, O), (Helpdesk, ORGANIZATION),...\n",
       "4    [[(This, O), (just, O), (happened, O), (..., O...\n",
       "3    [[(Another, O), (tale, O), (from, O), (the, O)...\n",
       "2    [[([, O), (Part, O), (1, O), (], O), ((, O), (...\n",
       "1    [[(>, O), ($, O), (Me, O), (-, O), (Hello, O),...\n",
       "0    [[(So, O), (my, O), (story, O), (starts, O), (...\n",
       "Name: classified_sents, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['classified_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most common entities (which are, of course, boring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 401),\n",
       " ('I', 245),\n",
       " ('the', 226),\n",
       " (',', 205),\n",
       " ('to', 197),\n",
       " ('a', 143),\n",
       " ('and', 135),\n",
       " ('>', 106),\n",
       " ('you', 102),\n",
       " ('of', 97)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if ent in entityCounts:\n",
    "                entityCounts[ent] += 1\n",
    "            else:\n",
    "                entityCounts[ent] = 1\n",
    "sortedEntities = sorted(entityCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedEntities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or those occurring only twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'Desk',\n",
       " 'busy',\n",
       " 'fix',\n",
       " 'received',\n",
       " 'couple',\n",
       " 'Windows',\n",
       " 'anymore',\n",
       " 'Sure',\n",
       " 'error',\n",
       " 'DVD',\n",
       " 'opened',\n",
       " 'There',\n",
       " 'upside',\n",
       " 'local',\n",
       " 'bane',\n",
       " 'existence',\n",
       " 'learn',\n",
       " 'sometimes',\n",
       " 'generic',\n",
       " 'Everyone',\n",
       " 'login',\n",
       " 'times',\n",
       " 'guy',\n",
       " 'asset',\n",
       " 'name',\n",
       " 'Computer',\n",
       " 'nothing',\n",
       " \"'P4ssword\",\n",
       " 'P',\n",
       " 'Everything',\n",
       " 'case',\n",
       " '*type',\n",
       " 'S',\n",
       " 'LOWERCASE',\n",
       " 'used',\n",
       " 'four',\n",
       " 'Original',\n",
       " 'cancer',\n",
       " 'month',\n",
       " 'live',\n",
       " 'brave',\n",
       " 'bitter',\n",
       " 'passed',\n",
       " 'ago',\n",
       " 'absolutely',\n",
       " 'ready',\n",
       " 'proud',\n",
       " 'above',\n",
       " 'completely',\n",
       " 'its',\n",
       " 'meant',\n",
       " 'both',\n",
       " 'sharing',\n",
       " 'making',\n",
       " '100',\n",
       " 'share',\n",
       " 'looking',\n",
       " 'ALL',\n",
       " 'whom',\n",
       " 'business',\n",
       " 'whose',\n",
       " 'stronger',\n",
       " 'bad',\n",
       " 'mess',\n",
       " 'turn',\n",
       " 'first',\n",
       " 'others',\n",
       " 'Here',\n",
       " 'suggested',\n",
       " 'videos',\n",
       " 'While',\n",
       " 'stand',\n",
       " 'certain',\n",
       " 'enjoy',\n",
       " 'well',\n",
       " 'drowned',\n",
       " 'soon',\n",
       " 'understand',\n",
       " 'risks',\n",
       " 'myself',\n",
       " 'point',\n",
       " 'future',\n",
       " 'avoid',\n",
       " 'thinking',\n",
       " 'information',\n",
       " 'insurance',\n",
       " 'site',\n",
       " 'step',\n",
       " 'guide',\n",
       " 'discover',\n",
       " 'order',\n",
       " '5',\n",
       " 'slightly',\n",
       " 'spent',\n",
       " 'moment',\n",
       " 'arms',\n",
       " 'idea',\n",
       " 'food',\n",
       " 'party',\n",
       " 'played',\n",
       " 'family',\n",
       " 'allowed',\n",
       " 'cry',\n",
       " 'pretty',\n",
       " 'nice',\n",
       " 'loved',\n",
       " 'mind',\n",
       " 'favor',\n",
       " 'watched',\n",
       " 'Things',\n",
       " '17',\n",
       " 'small',\n",
       " 'lived',\n",
       " 'living',\n",
       " 'themselves',\n",
       " 'potential',\n",
       " 'happiness',\n",
       " 'sound',\n",
       " 'situation',\n",
       " 'believe',\n",
       " 'mistakes',\n",
       " 'same',\n",
       " 'scenario',\n",
       " 'difference',\n",
       " 'glad',\n",
       " 'flaws',\n",
       " 'stupid',\n",
       " 'yourself',\n",
       " 'ok',\n",
       " 'In',\n",
       " 'comments',\n",
       " 'SO',\n",
       " 'random',\n",
       " 'request',\n",
       " 'Give',\n",
       " 'THIS',\n",
       " 'response',\n",
       " 'Thanks',\n",
       " 'tears',\n",
       " 'helped',\n",
       " 'reply',\n",
       " 'large',\n",
       " 'academic',\n",
       " 'organization',\n",
       " 'CEO',\n",
       " 'Of',\n",
       " 'course',\n",
       " 'mailboxes',\n",
       " 'Fail',\n",
       " '#',\n",
       " 'check',\n",
       " 'generate',\n",
       " '=',\n",
       " 'real',\n",
       " 'stopped',\n",
       " 'avalanche',\n",
       " 'died',\n",
       " 'systems',\n",
       " 'staff',\n",
       " 'brought',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'plugged',\n",
       " 'hear',\n",
       " 'occasionally',\n",
       " 'operate',\n",
       " 'drawer*',\n",
       " 'try',\n",
       " 'hit',\n",
       " '*I',\n",
       " 'echo',\n",
       " 'heard',\n",
       " 'seconds',\n",
       " 'nose',\n",
       " 'working',\n",
       " 'BING',\n",
       " 'THE',\n",
       " '*Note',\n",
       " 'yes',\n",
       " 'different',\n",
       " 'search',\n",
       " 'immediately',\n",
       " 'connection',\n",
       " 'Turns',\n",
       " 'shortcut',\n",
       " 'okay',\n",
       " 'computering',\n",
       " 'taking',\n",
       " 'Steve',\n",
       " 'XYZ',\n",
       " 'however',\n",
       " 'forwarded',\n",
       " 'using',\n",
       " 'meet',\n",
       " 'ran',\n",
       " 'mouse',\n",
       " 'closed',\n",
       " 'window',\n",
       " 'revealing',\n",
       " 'me*',\n",
       " 'shaking',\n",
       " 'lunch',\n",
       " 'yelled',\n",
       " 'needed',\n",
       " 'key',\n",
       " 'week',\n",
       " 'pointed',\n",
       " 'door',\n",
       " 'blinked',\n",
       " 'Then',\n",
       " 'command',\n",
       " 'three',\n",
       " 'web',\n",
       " 'pages',\n",
       " 'person',\n",
       " 'Whatever',\n",
       " 'um',\n",
       " 'wrong',\n",
       " 'mother',\n",
       " 'done',\n",
       " 'way',\n",
       " 'weeks',\n",
       " 'since',\n",
       " 'stuff',\n",
       " 'took',\n",
       " 'Wow',\n",
       " 'gildings',\n",
       " 'One',\n",
       " 'HR',\n",
       " 'select',\n",
       " '*Are',\n",
       " 'Ca',\n",
       " 'building',\n",
       " 'holiday',\n",
       " 'pay',\n",
       " 'gods',\n",
       " 'expire',\n",
       " '60',\n",
       " 'anyway',\n",
       " 'User',\n",
       " 'DeskMugPhonePencil1',\n",
       " 'Thursday',\n",
       " 'return',\n",
       " 'calls',\n",
       " 'often',\n",
       " 'issues',\n",
       " 'service',\n",
       " 'older',\n",
       " 'types',\n",
       " 'speak',\n",
       " 'box',\n",
       " 'properly',\n",
       " 'personally',\n",
       " 'ask',\n",
       " 'supervisor',\n",
       " 'earlier',\n",
       " 'visit',\n",
       " 'terrible',\n",
       " 'willing',\n",
       " 'nasty']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in sortedEntities if x[1] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also list the most common \"non-objects\". (We note that we're not graphing these because there are so few here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jack', 17),\n",
       " ('Google', 6),\n",
       " ('Smith', 5),\n",
       " ('Steve', 2),\n",
       " ('Citrix', 1),\n",
       " ('Nono', 1),\n",
       " ('Reddit', 1),\n",
       " ('Helpdesk', 1),\n",
       " ('UK', 1),\n",
       " ('CMD', 1)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonObjCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind == 'O':\n",
    "                continue\n",
    "            elif ent in nonObjCounts:\n",
    "                nonObjCounts[ent] += 1\n",
    "            else:\n",
    "                nonObjCounts[ent] = 1\n",
    "sortedNonObj = sorted(nonObjCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedNonObj[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the Organizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Google', 6), ('Citrix', 1), ('Helpdesk', 1), ('CMD', 1), ('GOOGLE', 1)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrgCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != 'ORGANIZATION':\n",
    "                continue\n",
    "            elif ent in OrgCounts:\n",
    "                OrgCounts[ent] += 1\n",
    "            else:\n",
    "                OrgCounts[ent] = 1\n",
    "sortedOrgs = sorted(OrgCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedOrgs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These, of course, have much smaller counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform NER on a (modest) subset of your corpus of interest. List all of the different kinds of entities tagged? What does their distribution suggest about the focus of your corpus? For a subset of your corpus, tally at least one type of named entity and calculate the Precision, Recall and F-score for the NER classification just performed (using your own hand-codings as \"ground truth\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>a</th>\n",
       "      <th>sentences</th>\n",
       "      <th>POS_sents</th>\n",
       "      <th>classified_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>[[To, our, shareholders, ,, customers, ,, part...</td>\n",
       "      <td>[[(To, TO), (our, PRP$), (shareholders, NNS), ...</td>\n",
       "      <td>[[(To, O), (our, O), (shareholders, O), (,, O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>[[To, our, shareholders, ,, customers, ,, part...</td>\n",
       "      <td>[[(To, TO), (our, PRP$), (shareholders, NNS), ...</td>\n",
       "      <td>[[(To, O), (our, O), (shareholders, O), (,, O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners and e...</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>[[To, our, shareholders, ,, customers, ,, part...</td>\n",
       "      <td>[[(To, TO), (our, PRP$), (shareholders, NNS), ...</td>\n",
       "      <td>[[(To, O), (our, O), (shareholders, O), (,, O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>[[To, our, shareholders, ,, customers, ,, part...</td>\n",
       "      <td>[[(To, TO), (our, PRP$), (shareholders, NNS), ...</td>\n",
       "      <td>[[(To, O), (our, O), (shareholders, O), (,, O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>To our shareholders, customers, partners, and ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>[[To, our, shareholders, ,, customers, ,, part...</td>\n",
       "      <td>[[(To, TO), (our, PRP$), (shareholders, NNS), ...</td>\n",
       "      <td>[[(To, O), (our, O), (shareholders, O), (,, O)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company                                               text  year  a  \\\n",
       "10  Microsoft   To our shareholders, customers, partners, and ...  2005  1   \n",
       "9   Microsoft   To our shareholders, customers, partners, and ...  2006  1   \n",
       "8   Microsoft   To our shareholders, customers, partners and e...  2007  1   \n",
       "7   Microsoft   To our shareholders, customers, partners, and ...  2008  1   \n",
       "6   Microsoft   To our shareholders, customers, partners, and ...  2009  1   \n",
       "\n",
       "                                            sentences  \\\n",
       "10  [[To, our, shareholders, ,, customers, ,, part...   \n",
       "9   [[To, our, shareholders, ,, customers, ,, part...   \n",
       "8   [[To, our, shareholders, ,, customers, ,, part...   \n",
       "7   [[To, our, shareholders, ,, customers, ,, part...   \n",
       "6   [[To, our, shareholders, ,, customers, ,, part...   \n",
       "\n",
       "                                            POS_sents  \\\n",
       "10  [[(To, TO), (our, PRP$), (shareholders, NNS), ...   \n",
       "9   [[(To, TO), (our, PRP$), (shareholders, NNS), ...   \n",
       "8   [[(To, TO), (our, PRP$), (shareholders, NNS), ...   \n",
       "7   [[(To, TO), (our, PRP$), (shareholders, NNS), ...   \n",
       "6   [[(To, TO), (our, PRP$), (shareholders, NNS), ...   \n",
       "\n",
       "                                     classified_sents  \n",
       "10  [[(To, O), (our, O), (shareholders, O), (,, O)...  \n",
       "9   [[(To, O), (our, O), (shareholders, O), (,, O)...  \n",
       "8   [[(To, O), (our, O), (shareholders, O), (,, O)...  \n",
       "7   [[(To, O), (our, O), (shareholders, O), (,, O)...  \n",
       "6   [[(To, O), (our, O), (shareholders, O), (,, O)...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microsoft['classified_sents'] = microsoft['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))\n",
    "microsoft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1209),\n",
       " ('and', 1025),\n",
       " ('.', 824),\n",
       " ('the', 734),\n",
       " ('to', 634),\n",
       " ('of', 496),\n",
       " ('in', 412),\n",
       " ('our', 338),\n",
       " ('we', 306),\n",
       " ('a', 296)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most common entities\n",
    "entityCounts = {}\n",
    "for entry in microsoft['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if ent in entityCounts:\n",
    "                entityCounts[ent] += 1\n",
    "            else:\n",
    "                entityCounts[ent] = 1\n",
    "sortedEntities = sorted(entityCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedEntities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Microsoft', 184),\n",
       " ('Dynamics', 15),\n",
       " ('Office', 13),\n",
       " ('Bing', 11),\n",
       " ('Skype', 9),\n",
       " ('Steven', 8),\n",
       " ('A.', 8),\n",
       " ('Ballmer', 8),\n",
       " ('Research', 7),\n",
       " ('Cortana', 7)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most common non-objects\n",
    "nonObjCounts = {}\n",
    "for entry in microsoft['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind == 'O':\n",
    "                continue\n",
    "            elif ent in nonObjCounts:\n",
    "                nonObjCounts[ent] += 1\n",
    "            else:\n",
    "                nonObjCounts[ent] = 1\n",
    "sortedNonObj = sorted(nonObjCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedNonObj[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Microsoft', 184),\n",
       " ('Dynamics', 15),\n",
       " ('Office', 13),\n",
       " ('Skype', 9),\n",
       " ('Research', 7),\n",
       " ('&', 6),\n",
       " ('Communications', 5),\n",
       " ('Services', 5),\n",
       " ('Devices', 5),\n",
       " ('Nokia', 5)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most common organizations\n",
    "OrgCounts = {}\n",
    "for entry in microsoft['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != 'ORGANIZATION':\n",
    "                continue\n",
    "            elif ent in OrgCounts:\n",
    "                OrgCounts[ent] += 1\n",
    "            else:\n",
    "                OrgCounts[ent] = 1\n",
    "sortedOrgs = sorted(OrgCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedOrgs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Microsoft', 12), ('Dynamics', 2), ('Skype', 1)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microsoft2012 = microsoft[microsoft.index==4]\n",
    "microsoft2012\n",
    "OrgCounts = {}\n",
    "a = []\n",
    "for entry in microsoft2012['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != 'ORGANIZATION':\n",
    "                if 'Dynamics' in ent:\n",
    "                    a.append(sentence)\n",
    "                continue\n",
    "            elif ent in OrgCounts:\n",
    "                OrgCounts[ent] += 1\n",
    "            else:\n",
    "                OrgCounts[ent] = 1\n",
    "sortedOrgs = sorted(OrgCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "for each in a:\n",
    "    print(each)\n",
    "sortedOrgs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TO', 'OUR', 'SHAREHOLDERS', ',', 'CUSTOMERS', ',', 'PARTNERS', 'AND', 'EMPLOYEES', ':', 'Last', 'year', 'was', 'a', 'big', 'year', 'â\\x80\\x94', 'we', 'delivered', 'strong', 'results', ',', 'launched', 'fantastic', 'new', 'products', 'and', 'services', ',', 'and', 'positioned', 'Microsoft', 'for', 'an', 'incredible', 'future', '.']\n",
      "['There', 'will', 'be', 'times', 'when', 'we', 'build', 'speciï¬\\x81c', 'devices', 'for', 'speciï¬\\x81c', 'purposes', ',', 'as', 'we', 'have', 'chosen', 'to', 'do', 'with', 'Xbox', 'and', 'the', 'recently', 'announced', 'Microsoft', 'Surface', '.']\n",
      "['So', 'right', 'out', 'of', 'the', 'box', ',', 'a', 'customer', 'will', 'get', 'a', 'stunning', 'device', 'that', 'is', 'connected', 'to', 'unique', 'communications', ',', 'productivity', 'and', 'entertainment', 'services', 'from', 'Microsoft', 'as', 'well', 'as', 'access', 'to', 'great', 'services', 'and', 'applications', 'from', 'our', 'partners', 'and', 'developers', 'around', 'the', 'world', '.']\n",
      "['Itâ\\x80\\x99s', 'one', 'more', 'reason', 'Microsoft', 'is', 'committed', 'to', 'delivering', 'devices', 'and', 'services', 'that', 'people', 'love', 'and', 'businesses', 'need', '.']\n",
      "['To', 'address', 'these', 'opportunities', ',', 'businesses', 'turn', 'to', 'Microsoft', '.']\n",
      "['They', 'count', 'on', 'our', 'worldâ\\x80\\x94class', 'business', 'applications', 'like', 'Microsoft', 'Dynamics', ',', 'Ofï¬\\x81ce', ',', 'Exchange', ',', 'SharePoint', ',', 'Lync', ',', 'and', 'our', 'business', 'intelligence', 'solutions', '.']\n",
      "['And', ',', 'increasingly', ',', 'businesses', 'of', 'all', 'sizes', 'are', 'looking', 'to', 'Microsoft', 'to', 'realize', 'the', 'beneï¬\\x81ts', 'of', 'the', 'cloud', '.']\n",
      "['All', 'the', 'online', 'services', 'people', 'use', 'today', 'â\\x80\\x94', 'both', 'from', 'Microsoft', 'and', 'other', 'companies', 'â\\x80\\x94', 'run', 'on', 'servers', 'in', 'datacenters', 'around', 'the', 'globe', '.']\n",
      "['Unique', 'to', 'Microsoft', ',', 'we', 'continue', 'to', 'design', 'and', 'deliver', 'worldâ\\x80\\x94class', 'cloud', 'solutions', 'that', 'allow', 'our', 'customers', 'to', 'move', 'to', 'the', 'cloud', 'on', 'their', 'terms', '.']\n",
      "['For', 'example', ',', 'a', 'company', 'can', 'choose', 'to', 'deploy', 'Ofï¬\\x81ce', 'or', 'Microsoft', 'Dynamics', 'on', 'premises', ',', 'as', 'a', 'cloud', 'service', 'or', 'a', 'combination', 'of', 'both', '.']\n",
      "['Our', 'Future', ':', 'Big', 'Opportunity', 'Thereâ\\x80\\x99s', 'a', 'remarkable', 'amount', 'of', 'opportunity', 'ahead', 'for', 'Microsoft', 'in', 'both', 'the', 'next', 'year', 'and', 'the', 'next', 'decade', '.']\n",
      "['It', 'truly', 'is', 'a', 'new', 'era', 'at', 'Microsoft', 'â\\x80\\x94', 'an', 'era', 'of', 'incredible', 'opportunity', 'for', 'us', ',', 'for', 'the', '8', 'million', 'developers', 'building', 'apps', 'for', 'our', 'devices', ',', 'for', 'the', 'more', 'than', '640,000', 'partners', 'worldwide', 'and', ',', 'most', 'important', ',', 'for', 'the', 'people', 'and', 'businesses', 'using', 'our', 'products', 'to', 'reach', 'their', 'full', 'potential', '.']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, row in microsoft2012.iterrows():\n",
    "    for each in row['sentences']:\n",
    "        if 'Microsoft' in each:\n",
    "            count +=1\n",
    "            print(each)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Microsoft 2012 Annual Letter to Shareholders the word 'Microsoft' was used 12 times. 9 times as the organziation and 3 times describing other objects (i.e. Microsoft Surface & Microsoft Dynamics). The NER classification algorithm classified the word all 12 times as an organization.\n",
    "\n",
    "Precision: .75\n",
    "Recall: 1.0\n",
    "F-Score: 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "Here we will introduce the Stanford Parser by feeding it tokenized text from our initial example sentences. The parser is a dependency parser, but this initial program outputs a simple, self-explanatory phrase-structure representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('NNP', ['Trayvon']), Tree('NNP', ['Benjamin']), Tree('NNP', ['Martin'])]), Tree('VP', [Tree('VBD', ['was']), Tree('NP', [Tree('NP', [Tree('DT', ['an']), Tree('NNP', ['African']), Tree('NNP', ['American'])]), Tree('PP', [Tree('IN', ['from']), Tree('NP', [Tree('NP', [Tree('NNP', ['Miami']), Tree('NNPS', ['Gardens'])]), Tree(',', [',']), Tree('NP', [Tree('NNP', ['Florida'])]), Tree(',', [',']), Tree('SBAR', [Tree('WHNP', [Tree('WP', ['who'])]), Tree('S', [Tree(',', [',']), Tree('PP', [Tree('IN', ['at']), Tree('ADJP', [Tree('NP', [Tree('CD', ['17']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])])]), Tree(',', [',']), Tree('VP', [Tree('VBD', ['was']), Tree('ADVP', [Tree('RB', ['fatally'])]), Tree('VP', [Tree('VBN', ['shot']), Tree('PP', [Tree('IN', ['by']), Tree('NP', [Tree('NP', [Tree('NNP', ['George']), Tree('NNP', ['Zimmerman'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['a']), Tree('NN', ['neighborhood']), Tree('NN', ['watch']), Tree('NN', ['volunteer'])]), Tree(',', [','])])]), Tree('PP', [Tree('IN', ['in']), Tree('NP', [Tree('NNP', ['Sanford']), Tree(',', [',']), Tree('NNP', ['Florida'])])])])])])])])])])]), Tree('.', ['.'])])])]\n"
     ]
    }
   ],
   "source": [
    "parses = list(stanford.parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "fourthSentParseTree = list(parses[3]) #iterators so be careful about re-running code, without re-running this block\n",
    "print(fourthSentParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are a common data structure and there are a large number of things to do with them. What we are intetered in is the relationship between different types of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeRelation(parsetree, relationType, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retList = []\n",
    "        for subT in parsetree.subtrees():\n",
    "            if subT.label() == relationType:\n",
    "                if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                    retList.append([(subT.label(), ' '.join(subT.leaves()))])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeSubRelation(parsetree, relationTypeScope, relationTypeTarget, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retSet = set()\n",
    "        for subT in parsetree.subtrees():\n",
    "            if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                if subT.label() == relationTypeScope:\n",
    "                    for subsub in subT.subtrees():\n",
    "                        if subsub.label()==relationTypeTarget:\n",
    "                            retSet.add(' '.join(subsub.leaves()))\n",
    "    return retSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('NP',\n",
       "   'an African American from Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')],\n",
       " [('NP',\n",
       "   'Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')]]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeRelation(fourthSentParseTree, 'NP', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Florida occurs twice in two different nested noun phrases in the sentence. \n",
    "\n",
    "We can also find all of the verbs within the noun phrase defined by one or more target words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shot'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeSubRelation(fourthSentParseTree, 'NP', 'VBN', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want to to look at the whole tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                   ROOT                                                                                                                       \n",
      "                                                                                                                    |                                                                                                                          \n",
      "                                                                                                                    S                                                                                                                         \n",
      "            ________________________________________________________________________________________________________|_______________________________________________________________________________________________________________________   \n",
      "           |                       VP                                                                                                                                                                                                       | \n",
      "           |              _________|______________                                                                                                                                                                                          |  \n",
      "           |             |                        NP                                                                                                                                                                                        | \n",
      "           |             |          ______________|________________                                                                                                                                                                         |  \n",
      "           |             |         |                               PP                                                                                                                                                                       | \n",
      "           |             |         |               ________________|___________                                                                                                                                                             |  \n",
      "           |             |         |              |                            NP                                                                                                                                                           | \n",
      "           |             |         |              |           _________________|____________________________________                                                                                                                        |  \n",
      "           |             |         |              |          |           |     |     |                             SBAR                                                                                                                     | \n",
      "           |             |         |              |          |           |     |     |    __________________________|______________________________                                                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |                                                         S                                                                                        | \n",
      "           |             |         |              |          |           |     |     |   |     ____________________________________________________|_______________________                                                                 |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |                                                 VP                                                               | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |    _____________________________________________|_______                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |                                               VP                                                       | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |      _________________________________________|________________________________________                |  \n",
      "           |             |         |              |          |           |     |     |   |    |           PP             |   |     |     |                      PP                                                          |               | \n",
      "           |             |         |              |          |           |     |     |   |    |    _______|____          |   |     |     |     _________________|__________                                                 |               |  \n",
      "           |             |         |              |          |           |     |     |   |    |   |           ADJP       |   |     |     |    |                            NP                                               PP              | \n",
      "           |             |         |              |          |           |     |     |   |    |   |        ____|____     |   |     |     |    |           _________________|________________________________     ___________|___            |  \n",
      "           NP            |         NP             |          NP          |     NP    |  WHNP  |   |       NP        |    |   |    ADVP   |    |          NP            |           NP                       |   |               NP          | \n",
      "    _______|_______      |    _____|_______       |      ____|_____      |     |     |   |    |   |    ___|____     |    |   |     |     |    |     _____|______       |    _______|_________________       |   |      _________|_____      |  \n",
      "  NNP     NNP     NNP   VBD  DT   NNP     NNP     IN   NNP        NNPS   ,    NNP    ,   WP   ,   IN  CD      NNS   JJ   ,  VBD    RB   VBN   IN  NNP          NNP     ,   DT      NN        NN      NN     ,   IN   NNP        ,    NNP    . \n",
      "   |       |       |     |   |     |       |      |     |          |     |     |     |   |    |   |   |        |    |    |   |     |     |    |    |            |      |   |       |         |       |      |   |     |         |     |     |  \n",
      "Trayvon Benjamin Martin was  an African American from Miami     Gardens  ,  Florida  ,  who   ,   at  17     years old   ,  was fatally shot  by George     Zimmerman  ,   a  neighborhood watch volunteer  ,   in Sanford      ,  Florida  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourthSentParseTree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ROOT                           \n",
      "                      |                              \n",
      "                      S                             \n",
      "       _______________|___________________________   \n",
      "      |                          VP               | \n",
      "      |                __________|___             |  \n",
      "      |               |              PP           | \n",
      "      |               |      ________|___         |  \n",
      "      NP              |     |            NP       | \n",
      "  ____|__________     |     |     _______|____    |  \n",
      " DT   JJ    JJ   NN  VBD    IN   DT      JJ   NN  . \n",
      " |    |     |    |    |     |    |       |    |   |  \n",
      "The quick brown fox jumped over the     lazy dog  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "list(parses[1])[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency parsing and graph representations\n",
    "\n",
    "Dependency parsing was developed to robustly capture linguistic dependencies from text. The complex tags associated with these parses are detailed [here]('http://universaldependencies.org/u/overview/syntax.html'). When parsing with the dependency parser, we will work directly from the untokenized text. Note that no *processing* takes place before parsing sentences--we do not remove so-called stop words or anything that plays a syntactic role in the sentence, although anaphora resolution and related normalization may be performed before or after parsing to enhance the value of information extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x7f3b425a4268>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'quick'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'brown'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [2, 3],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'fox'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'nmod': [9],\n",
      "                                      'nsubj': [4]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 0,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'jumped'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'over'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'lazy'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [8],\n",
      "                                      'case': [6],\n",
      "                                      'det': [7]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nmod',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'dog'}})\n"
     ]
    }
   ],
   "source": [
    "depParses = list(stanford.depParser.raw_parse_sents(text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "secondSentDepParseTree = list(depParses[1])[0] #iterators so be careful about re-running code, without re-running this block\n",
    "print(secondSentDepParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a graph and we can convert it to a dot file and use that to visulize it. Try traversing the tree and extracting elements that are nearby one another. We note that unless you have the graphviz successfully installed on your computer (which is not necessary to complete this homework), the following graphviz call will trigger an error. If you are interested in installing graphviz and working on a Mac, consider installing through [homebrew](https://brew.sh), a package manager (i.e., with the command \"brew install graphviz\", once brew is installed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"467pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 467.00 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-301 463,-301 463,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"250.5\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"250.5\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (jumped)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.5,-260.799C250.5,-249.163 250.5,-233.548 250.5,-220.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254,-220.175 250.5,-210.175 247,-220.175 254,-220.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (fox)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M225.609,-173.799C206.937,-160.895 181.185,-143.099 160.75,-128.978\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"162.57,-125.981 152.354,-123.175 158.591,-131.74 162.57,-125.981\"/>\n",
       "<text text-anchor=\"middle\" x=\"211.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node7\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"316.5\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (dog)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M263.856,-173.799C273.339,-161.587 286.224,-144.992 296.873,-131.278\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"299.795,-133.221 303.164,-123.175 294.266,-128.927 299.795,-133.221\"/>\n",
       "<text text-anchor=\"middle\" x=\"303.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"28.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (The)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"108.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (quick)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"195.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (brown)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.466,-86.799C92.7052,-74.1257 72.4484,-56.7335 56.1474,-42.7377\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.3715,-40.0342 48.5043,-36.1754 53.8115,-45.3452 58.3715,-40.0342\"/>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.655,-86.799C121.054,-75.1626 117.564,-59.5479 114.588,-46.2368\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.936,-45.1711 112.339,-36.1754 111.105,-46.6981 117.936,-45.1711\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.261,-86.799C151.031,-74.5865 164.306,-57.9921 175.278,-44.2776\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.246,-46.1706 181.76,-36.1754 172.78,-41.7977 178.246,-46.1706\"/>\n",
       "<text text-anchor=\"middle\" x=\"182\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"279.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (over)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>9&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M309.012,-86.799C303.847,-74.9322 296.88,-58.9279 291.013,-45.4488\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.177,-43.9475 286.976,-36.1754 287.758,-46.7414 294.177,-43.9475\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"354.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (the)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M324.19,-86.799C329.495,-74.9322 336.65,-58.9279 342.676,-45.4488\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"345.935,-46.7332 346.822,-36.1754 339.545,-43.8762 345.935,-46.7332\"/>\n",
       "<text text-anchor=\"middle\" x=\"347\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"429.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (lazy)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M339.367,-86.799C356.368,-74.0105 379.758,-56.4169 398.449,-42.3569\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"400.779,-44.9838 406.667,-36.1754 396.571,-39.3898 400.779,-44.9838\"/>\n",
       "<text text-anchor=\"middle\" x=\"396\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f3b81fcca90>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    secondSentGraph = graphviz.Source(secondSentDepParseTree.to_dot())\n",
    "except:\n",
    "    secondSentGraph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "secondSentGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"961pt\" height=\"566pt\"\n",
       " viewBox=\"0.00 0.00 961.00 566.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 562)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-562 957,-562 957,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"232\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node2\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"232\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (American)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;7 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M232,-521.799C232,-510.163 232,-494.548 232,-481.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"235.5,-481.175 232,-471.175 228.5,-481.175 235.5,-481.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"74\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (Martin)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193.462,-434.963C181.635,-429.483 168.668,-423.214 157,-417 141.139,-408.552 124.062,-398.448 109.546,-389.541\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.218,-386.459 100.872,-384.175 107.535,-392.412 111.218,-386.459\"/>\n",
       "<text text-anchor=\"middle\" x=\"172\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"158\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (was)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M217.025,-434.799C206.293,-422.471 191.673,-405.679 179.669,-391.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.159,-389.42 172.953,-384.175 176.879,-394.016 182.159,-389.42\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">cop</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"232\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (an)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M232,-434.799C232,-423.163 232,-407.548 232,-394.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"235.5,-394.175 232,-384.175 228.5,-394.175 235.5,-394.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (African)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.999,-434.799C261.295,-422.356 278.087,-405.364 291.784,-391.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.487,-393.748 299.027,-384.175 289.508,-388.828 294.487,-393.748\"/>\n",
       "<text text-anchor=\"middle\" x=\"309\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node9\" class=\"node\"><title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"417\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">10 (Gardens)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;10 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.249,-440.698C297.554,-434.849 321.499,-426.853 342,-417 357.504,-409.548 373.521,-399.277 386.753,-389.982\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"388.929,-392.729 395.012,-384.054 384.847,-387.042 388.929,-392.729\"/>\n",
       "<text text-anchor=\"middle\" x=\"384\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"41\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (Trayvon)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"145\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (Benjamin)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.322,-347.799C62.7596,-336.047 56.6219,-320.238 51.4211,-306.842\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.5501,-305.231 47.6681,-297.175 48.0246,-307.764 54.5501,-305.231\"/>\n",
       "<text text-anchor=\"middle\" x=\"89\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.456,-347.911C109.458,-342.777 116.513,-336.704 122,-330 127.594,-323.167 132.146,-314.75 135.68,-306.785\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.96,-308.01 139.487,-297.429 132.476,-305.372 138.96,-308.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"161\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>10&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372.659,-348.343C360.184,-343.054 346.805,-336.795 335,-330 321.639,-322.31 307.831,-312.393 296.247,-303.422\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.26,-300.552 288.243,-297.102 293.922,-306.046 298.26,-300.552\"/>\n",
       "<text text-anchor=\"middle\" x=\"347\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"355\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (Miami)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M388.011,-347.942C381.329,-342.879 374.786,-336.833 370,-330 365.3,-323.291 362.049,-315.086 359.809,-307.278\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"363.172,-306.293 357.412,-297.401 356.37,-307.945 363.172,-306.293\"/>\n",
       "<text text-anchor=\"middle\" x=\"399\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node12\" class=\"node\"><title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"451\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">12 (Florida)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M423.88,-347.799C428.581,-336.047 434.905,-320.238 440.263,-306.842\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"443.666,-307.76 444.13,-297.175 437.166,-305.16 443.666,-307.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"453\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">appos</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node13\" class=\"node\"><title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"543\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">23 (shot)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;23 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>10&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M445.132,-347.888C454.112,-342.301 464.041,-335.991 473,-330 485.787,-321.449 499.616,-311.685 511.579,-303.068\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"513.871,-305.73 519.918,-297.03 509.766,-300.06 513.871,-305.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"517\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node14\" class=\"node\"><title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"337\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">14 (who)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>23&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M510.212,-263.981C507.126,-262.889 504.023,-261.874 501,-261 457.617,-248.462 442.222,-261.441 401,-243 386.707,-236.606 372.772,-226.351 361.573,-216.788\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"363.739,-214.031 353.937,-210.012 359.093,-219.267 363.739,-214.031\"/>\n",
       "<text text-anchor=\"middle\" x=\"427.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubjpass</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node18\" class=\"node\"><title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"418\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">19 (old)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;19 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>23&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M510.439,-262.889C499.204,-257.185 486.749,-250.298 476,-243 464.63,-235.281 452.986,-225.644 443.143,-216.896\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.434,-214.248 435.675,-210.124 440.732,-219.434 445.434,-214.248\"/>\n",
       "<text text-anchor=\"middle\" x=\"491\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">advcl</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node19\" class=\"node\"><title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"498\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">21 (was)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;21 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>23&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M528.132,-260.935C523.834,-255.453 519.393,-249.192 516,-243 512.054,-235.799 508.676,-227.562 505.948,-219.879\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"509.218,-218.62 502.744,-210.233 502.575,-220.826 509.218,-218.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"537.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">auxpass</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node20\" class=\"node\"><title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"587\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">22 (fatally)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M551.904,-260.799C558.107,-248.817 566.492,-232.617 573.512,-219.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"576.62,-220.665 578.109,-210.175 570.404,-217.447 576.62,-220.665\"/>\n",
       "<text text-anchor=\"middle\" x=\"590.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node21\" class=\"node\"><title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"700\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">26 (Zimmerman)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;26 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>23&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M575.77,-263.362C588.753,-257.34 603.722,-250.116 617,-243 632.84,-234.511 649.913,-224.4 664.432,-215.499\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"666.441,-218.372 673.108,-210.138 662.761,-212.417 666.441,-218.372\"/>\n",
       "<text text-anchor=\"middle\" x=\"659\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node22\" class=\"node\"><title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"822\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">36 (Florida)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;36 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>23&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M575.639,-270.42C603.324,-263.796 644,-253.602 679,-243 709.824,-233.663 743.881,-221.817 771.024,-212\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"772.491,-215.19 780.693,-208.483 770.099,-208.612 772.491,-215.19\"/>\n",
       "<text text-anchor=\"middle\" x=\"738\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node15\" class=\"node\"><title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">16 (at)</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node16\" class=\"node\"><title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">17 (17)</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node17\" class=\"node\"><title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">18 (years)</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;17 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>18&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M439,-86.799C439,-75.1626 439,-59.5479 439,-46.2368\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"442.5,-46.1754 439,-36.1754 435.5,-46.1755 442.5,-46.1754\"/>\n",
       "<text text-anchor=\"middle\" x=\"464\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">nummod</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;16 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>19&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M405.858,-173.799C397.319,-161.702 385.745,-145.305 376.118,-131.667\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"378.75,-129.327 370.124,-123.175 373.031,-133.364 378.75,-129.327\"/>\n",
       "<text text-anchor=\"middle\" x=\"404\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;18 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>19&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422.25,-173.799C425.125,-162.163 428.982,-146.548 432.271,-133.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"435.756,-133.723 434.757,-123.175 428.96,-132.044 435.756,-133.723\"/>\n",
       "<text text-anchor=\"middle\" x=\"467\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod:npmod</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node23\" class=\"node\"><title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"535\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">24 (by)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;24 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>26&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M652.772,-173.869C639.668,-168.616 625.588,-162.494 613,-156 597.638,-148.075 581.429,-137.994 567.791,-128.962\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"569.487,-125.885 559.235,-123.212 565.583,-131.694 569.487,-125.885\"/>\n",
       "<text text-anchor=\"middle\" x=\"625\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node24\" class=\"node\"><title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"623\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">25 (George)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;25 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>26&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M671.555,-173.873C664.323,-168.701 656.929,-162.619 651,-156 644.797,-149.076 639.392,-140.545 635.029,-132.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"638.057,-130.736 630.4,-123.413 631.819,-133.913 638.057,-130.736\"/>\n",
       "<text text-anchor=\"middle\" x=\"680\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node25\" class=\"node\"><title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">31 (volunteer)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;31 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>26&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M706.071,-173.799C710.219,-162.047 715.798,-146.238 720.526,-132.842\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"723.91,-133.77 723.938,-123.175 717.309,-131.44 723.91,-133.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"732\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">appos</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node29\" class=\"node\"><title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"822\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">33 (in)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;33 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>36&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M822,-173.799C822,-162.163 822,-146.548 822,-133.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"825.5,-133.175 822,-123.175 818.5,-133.175 825.5,-133.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"834\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node30\" class=\"node\"><title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"910\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">34 (Sanford)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;34 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>36&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M839.808,-173.799C852.69,-161.356 870.282,-144.364 884.631,-130.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"887.457,-132.64 892.218,-123.175 882.594,-127.605 887.457,-132.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"900\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\"><title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"626\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">28 (a)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;28 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>31&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M708.954,-86.799C693.448,-74.1257 672.168,-56.7335 655.044,-42.7377\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"656.972,-39.7938 647.015,-36.1754 652.543,-45.2138 656.972,-39.7938\"/>\n",
       "<text text-anchor=\"middle\" x=\"693.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node27\" class=\"node\"><title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">29 (neighborhood)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M730,-86.799C730,-75.1626 730,-59.5479 730,-46.2368\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"733.5,-46.1754 730,-36.1754 726.5,-46.1755 733.5,-46.1754\"/>\n",
       "<text text-anchor=\"middle\" x=\"759\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node28\" class=\"node\"><title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"845\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">30 (watch)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M763.745,-86.9012C773.181,-81.6054 783.244,-75.453 792,-69 802.239,-61.4544 812.611,-52.1229 821.432,-43.5725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"824.105,-45.8504 828.742,-36.324 819.177,-40.8797 824.105,-45.8504\"/>\n",
       "<text text-anchor=\"middle\" x=\"838\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f3b82038748>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(depParses[3])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a dependency parse on the reddit sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "topPostDepParse = list(stanford.depParser.parse_sents(redditTopScores['sentences'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a few seconds, but now lets look at the parse tree from one of the processed sentences.\n",
    "\n",
    "The sentence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So anyway , I get a call from an older gentleman who 's quite bitter and mean right off the bat ( does n't like that I asked for his address / telephone number to verify the account , hates that he has to speak with a machine before reaching an agent , etc . ) .\n"
     ]
    }
   ],
   "source": [
    "targetSentence = 7\n",
    "print(' '.join(redditTopScores['sentences'][0][targetSentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which leads to a very rich dependancy tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"1107pt\" height=\"827pt\"\n",
       " viewBox=\"0.00 0.00 1107.00 827.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 823)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-823 1103,-823 1103,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"195\" y=\"-797.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"195\" y=\"-710.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (get)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195,-782.799C195,-771.163 195,-755.548 195,-742.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"198.5,-742.175 195,-732.175 191.5,-742.175 198.5,-742.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"206\" y=\"-753.8\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-623.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (So)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.995,-707.618C144.938,-702.29 111.414,-692.766 85,-678 72.7302,-671.141 60.7017,-661.418 50.8082,-652.367\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.0351,-649.656 43.3678,-645.321 48.2216,-654.738 53.0351,-649.656\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5\" y=\"-666.8\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-623.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (anyway)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.754,-696.008C160.287,-690.714 152.474,-684.536 146,-678 138.881,-670.813 132.204,-662.033 126.63,-653.847\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.446,-651.758 121.045,-645.302 123.586,-655.587 129.446,-651.758\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.5\" y=\"-666.8\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"195\" y=\"-623.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (I)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195,-695.799C195,-684.163 195,-668.548 195,-655.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"198.5,-655.175 195,-645.175 191.5,-655.175 198.5,-655.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-666.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-623.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (call)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.33,-695.905C217.796,-690.318 223.769,-684.004 229,-678 235.87,-670.114 243.012,-661.196 249.278,-653.097\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.15,-655.102 255.442,-645.031 246.589,-650.851 252.15,-655.102\"/>\n",
       "<text text-anchor=\"middle\" x=\"254.5\" y=\"-666.8\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node7\" class=\"node\"><title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"615\" y=\"-623.3\" font-family=\"Times,serif\" font-size=\"14.00\">34 (number)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;34 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.234,-707.488C290.934,-693.585 472.218,-656.896 562.445,-638.636\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"563.353,-642.023 572.46,-636.609 561.964,-635.163 563.353,-642.023\"/>\n",
       "<text text-anchor=\"middle\" x=\"441\" y=\"-666.8\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"173\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (a)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.775,-608.799C234.74,-596.241 215.526,-579.049 199.958,-565.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201.982,-562.235 192.196,-558.175 197.315,-567.452 201.982,-562.235\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.5\" y=\"-579.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node9\" class=\"node\"><title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\">11 (gentleman)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M268,-608.799C268,-597.163 268,-581.548 268,-568.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271.5,-568.175 268,-558.175 264.5,-568.175 271.5,-568.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-579.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node25\" class=\"node\"><title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"566\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\">25 (like)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;25 -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>34&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M605.084,-608.799C598.177,-596.817 588.838,-580.617 581.021,-567.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"583.928,-565.091 575.901,-558.175 577.863,-568.587 583.928,-565.091\"/>\n",
       "<text text-anchor=\"middle\" x=\"604\" y=\"-579.8\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node32\" class=\"node\"><title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"663\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\">33 (telephone)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;33 -->\n",
       "<g id=\"edge31\" class=\"edge\"><title>34&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M624.714,-608.799C631.48,-596.817 640.628,-580.617 648.286,-567.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"651.431,-568.604 653.301,-558.175 645.336,-565.162 651.431,-568.604\"/>\n",
       "<text text-anchor=\"middle\" x=\"671\" y=\"-579.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node33\" class=\"node\"><title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"782\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\">36 (verify)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;36 -->\n",
       "<g id=\"edge32\" class=\"edge\"><title>34&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M657.848,-611.093C672.736,-605.407 689.363,-598.479 704,-591 719.51,-583.075 735.854,-572.909 749.552,-563.816\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"751.8,-566.521 758.136,-558.029 747.887,-560.717 751.8,-566.521\"/>\n",
       "<text text-anchor=\"middle\" x=\"736\" y=\"-579.8\" font-family=\"Times,serif\" font-size=\"14.00\">acl</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>11&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.934,-521.975C219.325,-516.444 206.537,-510.145 195,-504 178.857,-495.402 161.385,-485.273 146.505,-476.388\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147.984,-473.193 137.61,-471.041 144.377,-479.193 147.984,-473.193\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (an)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.608,-521.799C239.751,-509.356 223.559,-492.364 210.351,-478.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.8,-476 203.367,-471.175 207.732,-480.829 212.8,-476\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node12\" class=\"node\"><title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">10 (older)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M268,-521.799C268,-510.163 268,-494.548 268,-481.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271.5,-481.175 268,-471.175 264.5,-481.175 271.5,-481.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"283.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node13\" class=\"node\"><title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"357\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">15 (bitter)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.01,-521.799C299.16,-509.241 317.16,-492.049 331.745,-478.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"334.202,-480.613 339.016,-471.175 329.367,-475.551 334.202,-480.613\"/>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\"><title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"158\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">12 (who)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;12 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>15&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.234,-438.183C318.122,-437.074 315.013,-435.998 312,-435 284.356,-425.847 275.93,-428.081 249,-417 230.293,-409.302 210.5,-398.746 194.169,-389.316\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.877,-386.26 185.481,-384.218 192.334,-392.297 195.877,-386.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"264\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\"><title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"236\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">13 (&#39;s)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;13 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>15&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M329.85,-434.899C321.189,-429.312 311.619,-423 303,-417 290.73,-408.459 277.488,-398.697 266.042,-390.079\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.15,-387.285 258.064,-384.04 263.925,-392.866 268.15,-387.285\"/>\n",
       "<text text-anchor=\"middle\" x=\"313\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">cop</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\"><title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">14 (quite)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.809,-434.773C339.989,-429.285 336.036,-423.06 333,-417 329.345,-409.704 326.177,-401.438 323.599,-393.758\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"326.907,-392.612 320.558,-384.13 320.232,-394.72 326.907,-392.612\"/>\n",
       "<text text-anchor=\"middle\" x=\"355.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"400\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">16 (and)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M367.908,-434.799C371.295,-429.207 374.939,-422.916 378,-417 381.861,-409.538 385.684,-401.252 389.034,-393.607\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"392.268,-394.946 392.99,-384.375 385.834,-392.188 392.268,-394.946\"/>\n",
       "<text text-anchor=\"middle\" x=\"392.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">cc</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"486\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">17 (mean)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383.105,-434.799C402.776,-421.838 429.937,-403.941 451.415,-389.789\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"453.509,-392.6 459.934,-384.175 449.658,-386.755 453.509,-392.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"442\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"445\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">18 (right)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M465.866,-347.721C460.936,-342.509 456.171,-336.444 453,-330 449.584,-323.059 447.571,-314.982 446.401,-307.369\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.878,-306.97 445.274,-297.428 442.922,-307.759 449.878,-306.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"475.5\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node20\" class=\"node\"><title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"527\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">21 (bat)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;21 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>17&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M494.297,-347.799C500.021,-335.932 507.741,-319.928 514.242,-306.449\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"517.523,-307.703 518.715,-297.175 511.218,-304.662 517.523,-307.703\"/>\n",
       "<text text-anchor=\"middle\" x=\"525\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node21\" class=\"node\"><title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"480\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">19 (off)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;19 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>21&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M517.489,-260.799C510.863,-248.817 501.906,-232.617 494.408,-219.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"497.399,-217.233 489.497,-210.175 491.273,-220.62 497.399,-217.233\"/>\n",
       "<text text-anchor=\"middle\" x=\"519\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node22\" class=\"node\"><title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">20 (the)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;20 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>21&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M533.071,-260.799C537.219,-249.047 542.798,-233.238 547.526,-219.842\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"550.91,-220.77 550.938,-210.175 544.309,-218.44 550.91,-220.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node23\" class=\"node\"><title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"486\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">23 (does)</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node24\" class=\"node\"><title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"566\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">24 (n&#39;t)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;23 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>25&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M549.811,-521.799C538.1,-509.356 522.108,-492.364 509.063,-478.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"511.568,-476.059 502.165,-471.175 506.47,-480.856 511.568,-476.059\"/>\n",
       "<text text-anchor=\"middle\" x=\"541\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">aux</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>25&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M566,-521.799C566,-510.163 566,-494.548 566,-481.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"569.5,-481.175 566,-471.175 562.5,-481.175 569.5,-481.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"576\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">neg</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\"><title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"649\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">28 (asked)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;28 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>25&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M582.796,-521.799C594.946,-509.356 611.538,-492.364 625.072,-478.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"627.746,-480.775 632.229,-471.175 622.738,-475.885 627.746,-480.775\"/>\n",
       "<text text-anchor=\"middle\" x=\"631.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\"><title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"572\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">26 (that)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;26 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>28&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M632.431,-434.663C627.14,-429.064 621.287,-422.803 616,-417 608.641,-408.922 600.72,-399.995 593.654,-391.946\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"596.144,-389.476 586.925,-384.254 590.875,-394.085 596.144,-389.476\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\"><title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"649\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">27 (I)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;27 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>28&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M649,-434.799C649,-423.163 649,-407.548 649,-394.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"652.5,-394.175 649,-384.175 645.5,-394.175 652.5,-394.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"664\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node29\" class=\"node\"><title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"736\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">31 (address)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;31 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>28&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M666.606,-434.799C679.341,-422.356 696.733,-405.364 710.919,-391.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"713.714,-393.667 718.42,-384.175 708.822,-388.66 713.714,-393.667\"/>\n",
       "<text text-anchor=\"middle\" x=\"713\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\"><title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">29 (for)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M721.834,-347.799C711.777,-335.587 698.111,-318.992 686.817,-305.278\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"689.203,-302.67 680.144,-297.175 683.8,-307.12 689.203,-302.67\"/>\n",
       "<text text-anchor=\"middle\" x=\"717\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\"><title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"743\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">30 (his)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M737.417,-347.799C738.375,-336.163 739.661,-320.548 740.757,-307.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"744.253,-307.429 741.586,-297.175 737.277,-306.854 744.253,-307.429\"/>\n",
       "<text text-anchor=\"middle\" x=\"769\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node34\" class=\"node\"><title>35</title>\n",
       "<text text-anchor=\"middle\" x=\"782\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">35 (to)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;35 -->\n",
       "<g id=\"edge33\" class=\"edge\"><title>36&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M782,-521.799C782,-510.163 782,-494.548 782,-481.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"785.5,-481.175 782,-471.175 778.5,-481.175 785.5,-481.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"796.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 38 -->\n",
       "<g id=\"node35\" class=\"node\"><title>38</title>\n",
       "<text text-anchor=\"middle\" x=\"878\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">38 (account)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;38 -->\n",
       "<g id=\"edge34\" class=\"edge\"><title>36&#45;&gt;38</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M801.427,-521.799C815.61,-509.241 835.027,-492.049 850.758,-478.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"853.435,-480.425 858.602,-471.175 848.795,-475.184 853.435,-480.425\"/>\n",
       "<text text-anchor=\"middle\" x=\"847.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node36\" class=\"node\"><title>37</title>\n",
       "<text text-anchor=\"middle\" x=\"825\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">37 (the)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;37 -->\n",
       "<g id=\"edge35\" class=\"edge\"><title>38&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M867.275,-434.799C859.732,-422.702 849.508,-406.305 841.004,-392.667\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"843.97,-390.809 835.709,-384.175 838.03,-394.513 843.97,-390.809\"/>\n",
       "<text text-anchor=\"middle\" x=\"862.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node37\" class=\"node\"><title>40</title>\n",
       "<text text-anchor=\"middle\" x=\"908\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">40 (hates)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;40 -->\n",
       "<g id=\"edge36\" class=\"edge\"><title>38&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M884.071,-434.799C888.219,-423.047 893.798,-407.238 898.526,-393.842\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"901.91,-394.77 901.938,-384.175 895.309,-392.44 901.91,-394.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"906\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 54 -->\n",
       "<g id=\"node38\" class=\"node\"><title>54</title>\n",
       "<text text-anchor=\"middle\" x=\"991\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">54 (etc)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;54 -->\n",
       "<g id=\"edge37\" class=\"edge\"><title>38&#45;&gt;54</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M900.867,-434.799C917.868,-422.01 941.258,-404.417 959.949,-390.357\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"962.279,-392.984 968.167,-384.175 958.071,-387.39 962.279,-392.984\"/>\n",
       "<text text-anchor=\"middle\" x=\"953\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 43 -->\n",
       "<g id=\"node39\" class=\"node\"><title>43</title>\n",
       "<text text-anchor=\"middle\" x=\"827\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">43 (has)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;43 -->\n",
       "<g id=\"edge38\" class=\"edge\"><title>40&#45;&gt;43</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M891.608,-347.799C879.751,-335.356 863.559,-318.364 850.351,-304.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"852.8,-302 843.367,-297.175 847.732,-306.829 852.8,-302\"/>\n",
       "<text text-anchor=\"middle\" x=\"890.5\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g id=\"node40\" class=\"node\"><title>50</title>\n",
       "<text text-anchor=\"middle\" x=\"970\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">50 (reaching)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;50 -->\n",
       "<g id=\"edge39\" class=\"edge\"><title>40&#45;&gt;50</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M920.547,-347.799C929.455,-335.587 941.559,-318.992 951.562,-305.278\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"954.407,-307.317 957.472,-297.175 948.751,-303.192 954.407,-307.317\"/>\n",
       "<text text-anchor=\"middle\" x=\"957\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">advcl</text>\n",
       "</g>\n",
       "<!-- 41 -->\n",
       "<g id=\"node41\" class=\"node\"><title>41</title>\n",
       "<text text-anchor=\"middle\" x=\"715\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">41 (that)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;41 -->\n",
       "<g id=\"edge40\" class=\"edge\"><title>43&#45;&gt;41</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M796.722,-260.854C787.882,-255.466 778.356,-249.277 770,-243 759.521,-235.128 748.7,-225.633 739.458,-217.041\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"741.778,-214.419 732.107,-210.092 736.969,-219.505 741.778,-214.419\"/>\n",
       "<text text-anchor=\"middle\" x=\"784.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 42 -->\n",
       "<g id=\"node42\" class=\"node\"><title>42</title>\n",
       "<text text-anchor=\"middle\" x=\"793\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">42 (he)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;42 -->\n",
       "<g id=\"edge41\" class=\"edge\"><title>43&#45;&gt;42</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M817.449,-260.821C814.535,-255.23 811.456,-248.935 809,-243 805.981,-235.705 803.173,-227.622 800.779,-220.119\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"804.07,-218.91 797.79,-210.377 797.378,-220.964 804.07,-218.91\"/>\n",
       "<text text-anchor=\"middle\" x=\"824\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 45 -->\n",
       "<g id=\"node43\" class=\"node\"><title>45</title>\n",
       "<text text-anchor=\"middle\" x=\"876\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">45 (speak)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;45 -->\n",
       "<g id=\"edge42\" class=\"edge\"><title>43&#45;&gt;45</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M836.916,-260.799C843.823,-248.817 853.162,-232.617 860.979,-219.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"864.137,-220.587 866.099,-210.175 858.072,-217.091 864.137,-220.587\"/>\n",
       "<text text-anchor=\"middle\" x=\"873\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">xcomp</text>\n",
       "</g>\n",
       "<!-- 49 -->\n",
       "<g id=\"node48\" class=\"node\"><title>49</title>\n",
       "<text text-anchor=\"middle\" x=\"970\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">49 (before)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;49 -->\n",
       "<g id=\"edge47\" class=\"edge\"><title>50&#45;&gt;49</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M970,-260.799C970,-249.163 970,-233.548 970,-220.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"973.5,-220.175 970,-210.175 966.5,-220.175 973.5,-220.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"984.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node49\" class=\"node\"><title>52</title>\n",
       "<text text-anchor=\"middle\" x=\"1063\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">52 (agent)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;52 -->\n",
       "<g id=\"edge48\" class=\"edge\"><title>50&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M988.82,-260.799C1002.56,-248.241 1021.37,-231.049 1036.61,-217.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1039.19,-219.505 1044.21,-210.175 1034.47,-214.338 1039.19,-219.505\"/>\n",
       "<text text-anchor=\"middle\" x=\"1034.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 44 -->\n",
       "<g id=\"node44\" class=\"node\"><title>44</title>\n",
       "<text text-anchor=\"middle\" x=\"850\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">44 (to)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;44 -->\n",
       "<g id=\"edge43\" class=\"edge\"><title>45&#45;&gt;44</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M870.739,-173.799C867.144,-162.047 862.308,-146.238 858.211,-132.842\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"861.526,-131.714 855.254,-123.175 854.832,-133.762 861.526,-131.714\"/>\n",
       "<text text-anchor=\"middle\" x=\"878.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 48 -->\n",
       "<g id=\"node45\" class=\"node\"><title>48</title>\n",
       "<text text-anchor=\"middle\" x=\"940\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">48 (machine)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;48 -->\n",
       "<g id=\"edge44\" class=\"edge\"><title>45&#45;&gt;48</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M888.951,-173.799C898.147,-161.587 910.641,-144.992 920.967,-131.278\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"923.849,-133.269 927.068,-123.175 918.257,-129.059 923.849,-133.269\"/>\n",
       "<text text-anchor=\"middle\" x=\"927\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node46\" class=\"node\"><title>46</title>\n",
       "<text text-anchor=\"middle\" x=\"900\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">46 (with)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;46 -->\n",
       "<g id=\"edge45\" class=\"edge\"><title>48&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M931.905,-86.799C926.321,-74.9322 918.79,-58.9279 912.446,-45.4488\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"915.507,-43.7333 908.083,-36.1754 909.174,-46.7139 915.507,-43.7333\"/>\n",
       "<text text-anchor=\"middle\" x=\"934\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 47 -->\n",
       "<g id=\"node47\" class=\"node\"><title>47</title>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">47 (a)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;47 -->\n",
       "<g id=\"edge46\" class=\"edge\"><title>48&#45;&gt;47</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M947.892,-86.799C953.337,-74.9322 960.68,-58.9279 966.865,-45.4488\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"970.13,-46.724 971.12,-36.1754 963.768,-43.8048 970.13,-46.724\"/>\n",
       "<text text-anchor=\"middle\" x=\"969.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node50\" class=\"node\"><title>51</title>\n",
       "<text text-anchor=\"middle\" x=\"1063\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">51 (an)</text>\n",
       "</g>\n",
       "<!-- 52&#45;&gt;51 -->\n",
       "<g id=\"edge49\" class=\"edge\"><title>52&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1063,-173.799C1063,-162.163 1063,-146.548 1063,-133.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1066.5,-133.175 1063,-123.175 1059.5,-133.175 1066.5,-133.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"1071.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f3b425484e0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(topPostDepParse[targetSentence])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, parse a (modest) subset of your corpus of interest. How deep are the phrase structure and dependency parse trees nested? How does parse depth relate to perceived sentence complexity? What are five things you can extract from these parses for subsequent analysis? (e.g., nouns collocated in a noun phrase; adjectives that modify a noun; etc.) Capture these sets of things for a focal set of words (e.g., \"Bush\", \"Obama\", \"Trump\"). What do they reveal about the roles that these entities are perceived to play in the social world inscribed by your texts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "micro12letter = list(stanford.depParser.parse_sents(microsoft2012['sentences'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"847pt\" height=\"653pt\"\n",
       " viewBox=\"0.00 0.00 847.00 653.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 649)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-649 843,-649 843,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-623.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (shift)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177,-608.799C177,-597.163 177,-581.548 177,-568.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.5,-568.175 177,-558.175 173.5,-568.175 180.5,-568.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-579.8\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"30\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (This)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.923,-526.086C133.262,-519.889 117.05,-512.067 103,-504 88.9286,-495.921 74.0416,-485.997 61.4075,-477.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.2361,-474.132 53.0584,-471.188 59.1791,-479.836 63.2361,-474.132\"/>\n",
       "<text text-anchor=\"middle\" x=\"118\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (is)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.43,-521.799C151.987,-509.471 137.763,-492.679 126.083,-478.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.683,-476.544 119.549,-471.175 123.341,-481.068 128.683,-476.544\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">cop</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (a)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>5&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177,-521.799C177,-510.163 177,-494.548 177,-481.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.5,-481.175 177,-471.175 173.5,-481.175 180.5,-481.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (signiï¬cant)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197.236,-521.799C212.146,-509.126 232.608,-491.734 249.073,-477.738\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"251.441,-480.319 256.794,-471.175 246.907,-474.985 251.441,-480.319\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node7\" class=\"node\"><title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"378\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">11 (do)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;11 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M207.092,-527.922C224.904,-521.241 247.853,-512.42 268,-504 298.157,-491.396 307.16,-486.567 340.247,-471.353\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"342.091,-474.358 349.726,-467.012 339.177,-467.993 342.091,-474.358\"/>\n",
       "<text text-anchor=\"middle\" x=\"324\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"259\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (what)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351.353,-434.886C342.853,-429.298 333.46,-422.989 325,-417 313.032,-408.528 300.124,-398.87 288.924,-390.315\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290.799,-387.342 280.736,-384.027 286.535,-392.894 290.799,-387.342\"/>\n",
       "<text text-anchor=\"middle\" x=\"337.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"338\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">10 (we)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M369.627,-434.945C366.855,-429.25 363.772,-422.863 361,-417 357.382,-409.347 353.513,-401.003 350.001,-393.362\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.135,-391.8 345.789,-384.166 346.771,-394.715 353.135,-391.8\"/>\n",
       "<text text-anchor=\"middle\" x=\"376\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node12\" class=\"node\"><title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"417\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">12 (and)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M385.892,-434.799C391.337,-422.932 398.68,-406.928 404.865,-393.449\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"408.13,-394.724 409.12,-384.175 401.768,-391.805 408.13,-394.724\"/>\n",
       "<text text-anchor=\"middle\" x=\"405.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">cc</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node13\" class=\"node\"><title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"496\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">15 (see)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M401.879,-434.799C419.713,-421.953 444.277,-404.258 463.839,-390.167\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"466.088,-392.86 472.156,-384.175 461.997,-387.18 466.088,-392.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"456\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (both)</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (in)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.512,-347.799C246.347,-335.932 239.38,-319.928 233.513,-306.449\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"236.677,-304.947 229.476,-297.175 230.258,-307.741 236.677,-304.947\"/>\n",
       "<text text-anchor=\"middle\" x=\"253\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.69,-347.799C271.995,-335.932 279.15,-319.928 285.176,-306.449\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"288.435,-307.733 289.322,-297.175 282.045,-304.876 288.435,-307.733\"/>\n",
       "<text text-anchor=\"middle\" x=\"292\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"415\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">13 (how)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>15&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M468.323,-347.999C460.931,-342.747 453.265,-336.593 447,-330 440.294,-322.944 434.181,-314.288 429.135,-306.173\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.022,-304.18 423.918,-297.356 425.998,-307.745 432.022,-304.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.5\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"496\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">14 (we)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M496,-347.799C496,-336.163 496,-320.548 496,-307.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"499.5,-307.175 496,-297.175 492.5,-307.175 499.5,-307.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node16\" class=\"node\"><title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"581\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">17 (â)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M513.201,-347.799C525.644,-335.356 542.636,-318.364 556.496,-304.504\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"559.228,-306.721 563.825,-297.175 554.279,-301.772 559.228,-306.721\"/>\n",
       "<text text-anchor=\"middle\" x=\"561.5\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"541\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">16 (ourselves)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>17&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M572.905,-260.799C567.321,-248.932 559.79,-232.928 553.446,-219.449\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"556.507,-217.733 549.083,-210.175 550.174,-220.714 556.507,-217.733\"/>\n",
       "<text text-anchor=\"middle\" x=\"578\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node18\" class=\"node\"><title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"648\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">20 (devices)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;20 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>17&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M594.558,-260.799C604.185,-248.587 617.265,-231.992 628.075,-218.278\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"631.02,-220.196 634.462,-210.175 625.522,-215.862 631.02,-220.196\"/>\n",
       "<text text-anchor=\"middle\" x=\"634\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"538\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">18 (as)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>20&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.779,-173.959C614.756,-168.375 605.913,-162.049 598,-156 587.12,-147.682 575.486,-138.145 565.386,-129.645\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"567.55,-126.891 557.659,-123.094 563.023,-132.23 567.55,-126.891\"/>\n",
       "<text text-anchor=\"middle\" x=\"610\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\"><title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"610\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">19 (a)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>20&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M640.31,-173.799C635.005,-161.932 627.85,-145.928 621.824,-132.449\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"624.955,-130.876 617.678,-123.175 618.565,-133.733 624.955,-130.876\"/>\n",
       "<text text-anchor=\"middle\" x=\"639.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node21\" class=\"node\"><title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"686\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">21 (and)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;21 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>20&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M655.69,-173.799C660.995,-161.932 668.15,-145.928 674.176,-132.449\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"677.435,-133.733 678.322,-123.175 671.045,-130.876 677.435,-133.733\"/>\n",
       "<text text-anchor=\"middle\" x=\"675.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">cc</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node22\" class=\"node\"><title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"781\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">23 (company)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;23 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>20&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M674.915,-173.799C695.285,-160.78 723.448,-142.781 745.637,-128.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"747.584,-131.51 754.125,-123.175 743.814,-125.611 747.584,-131.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"734\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\"><title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"781\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">22 (services)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M781,-86.799C781,-75.1626 781,-59.5479 781,-46.2368\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"784.5,-46.1754 781,-36.1754 777.5,-46.1755 784.5,-46.1754\"/>\n",
       "<text text-anchor=\"middle\" x=\"810\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f3b81b7b978>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(micro12letter[targetSentence])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph is interesting  because while the upper echelon of the graph is not telling, the bottom right can describe microsoft as a 'device' company that provides mostly 'services'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('PP', [Tree('IN', ['In']), Tree('NP', [Tree('NN', ['addition'])])]), Tree(',', [',']), Tree('NP', [Tree('PRP', ['we'])]), Tree('VP', [Tree('VBD', ['returned']), Tree('NP', [Tree('QP', [Tree('$', ['$']), Tree('CD', ['10.7']), Tree('CD', ['billion'])])]), Tree('PP', [Tree('TO', ['to']), Tree('NP', [Tree('NNS', ['shareholders'])])]), Tree('PP', [Tree('IN', ['through']), Tree('NP', [Tree('NN', ['stock']), Tree('NNS', ['buybacks']), Tree('CC', ['and']), Tree('NNS', ['dividends'])])])]), Tree('.', ['.'])])])]\n"
     ]
    }
   ],
   "source": [
    "parsed = list(stanford.parser.parse_sents(microsoft2012.sentences.sum())) \n",
    "sentMicroParseTree = list(parsed[3]) \n",
    "print(sentMicroParseTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('NP', 'stock buybacks and dividends')]]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeRelation(sentMicroParseTree, 'NP', 'stock','dividends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             ROOT                                                               \n",
      "                                              |                                                                  \n",
      "                                              S                                                                 \n",
      "      ________________________________________|_______________________________________________________________   \n",
      "     |            |   |                                         VP                                            | \n",
      "     |            |   |      ___________________________________|_________________                            |  \n",
      "     PP           |   |     |          NP               PP                        PP                          | \n",
      "  ___|_____       |   |     |          |             ___|_______            ______|______                     |  \n",
      " |         NP     |   NP    |          QP           |           NP         |             NP                   | \n",
      " |         |      |   |     |       ___|______      |           |          |       ______|_____________       |  \n",
      " IN        NN     ,  PRP   VBD     $   CD     CD    TO         NNS         IN     NN    NNS     CC    NNS     . \n",
      " |         |      |   |     |      |   |      |     |           |          |      |      |      |      |      |  \n",
      " In     addition  ,   we returned  $  10.7 billion  to     shareholders through stock buybacks and dividends  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentMicroParseTree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed sentences describe that Microsoft is a services/device platform company that returns money to shareholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction\n",
    "\n",
    "Information extraction approaches typically (as here, with Stanford's Open IE engine) ride atop the dependency parse of a sentence. They are a pre-coded example of the type analyzed in the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.8 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 12.434 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [14.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0261 seconds]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ieDF = stanford.openIE(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`openIE()` prints everything stanford core produces and we can see from looking at it that initializing the dependency parser takes most of the time, so calling the function will always take at least 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [certainty, subject, verb, object]\n",
       "Index: []"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No buffalos (because there were no verbs), but the rest is somewhat promising. Note, however, that it abandoned the key theme of the sentence about the tragic Trayvon Martin death (\"fatally shot\"), likely because it was buried so deeply within the complex phrase structure. This is obviously a challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">How would you extract relevant information about the Trayvon Martin sentence directly from the dependency parse (above)? Code an example here. (For instance, what compound nouns show up with what verb phrases within the sentence?) How could these approaches inform your research project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server on http://10.50.221.87:16432 , please wait a few seconds\n",
      "click Kernel -> Then Interupt to stop           (((っ･д･)っ             \n",
      "Exiting (ノ≧▽≦)ノ\n"
     ]
    }
   ],
   "source": [
    "#having trouble with the stanford.openIE(), copying sentence to the stanford server\n",
    "stanford.startCoreServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: on the RCC server, I have access to firefox, which is not compatible with the stanford server linked above. Therefore, on my home computer, I typed the above sentence into the Stanford Parser found at https://nlp.stanford.edu/software/lex-parser.shtml in the 'online' link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find the compound nouns 'George Zimmerman' and shot are linked, but not 'Trayvon Martin' and shot. However, 'was' and 'shot' are linked, as well as, 'who' and 'shot.' Adjectives are better linked to the nouns. This infers that descriptions of actors are likely more accurate than their actions, if only because there was no clear identification of who got shot and who was shooting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also look for subject, object, target triples in one of the reddit stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 8.811 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [10.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0264 seconds]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ieDF = stanford.openIE(redditTopScores['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [certainty, subject, verb, object]\n",
       "Index: []"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost 200 triples in only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(redditTopScores['sentences'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentences and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(s) for s in redditTopScores['sentences'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find at the most common subject in this story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: subject, dtype: int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I is followed by various male pronouns and compound nouns (e.g., \"old man\"). 'I' occures most often with the following verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: verb, dtype: int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: object, dtype: int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run the corenlp server. When you run this server (with the command below), you can click on the browswer link provided to experiment with it. Note that when we run the server, executing the command below, it interrupts the current jupyter process and you will not be able to run code here again (processes will \"hang\" and never finish) until you interrup the process by clicking \"Kernel\" and then \"Interrupt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server on http://10.50.222.119:16432 , please wait a few seconds\n",
      "click Kernel -> Then Interupt to stop   (((っ･д･)っ                     \n",
      "Exiting (ノ≧▽≦)ノ\n"
     ]
    }
   ],
   "source": [
    "stanford.startCoreServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the stanford server is not compatible on firefox, which is the only web browser I have available on RCC. Therefore, I typed the sentence into the Stanford parser provided at the 'online' link at this page: https://nlp.stanford.edu/software/lex-parser.shtml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found compound noun 'George Zimmerman' linked with verb 'shot' however not 'Trayvon Martin.' I found 'who' and 'shot' linked, also 'was' and 'shot' were linked. Meanwhile, the adjectives were clearly linked with the compound nouns. Therefore, I infer that descriptors of actors may be easier for the algorithm to uncover than their actual actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform open information extraction on a modest subset of texts relevant to your final project. Analyze the relative attachment of several subjects relative to verbs and objects and visa versa. Describe how you would select among these statements to create a database of high-value statements for your project and then do it by extracting relevant statements into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
